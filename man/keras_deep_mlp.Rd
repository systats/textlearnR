% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/keras_deep_mlp.R
\name{keras_deep_mlp}
\alias{keras_deep_mlp}
\title{keras deep mlp}
\usage{
keras_deep_mlp(input_dim, embed_dim = 64, seq_len, hidden_dims = c(256,
  128, 64), hidden_fun = "relu", output_fun = "softmax", output_dim)
}
\arguments{
\item{input_dim}{Number of unique vocabluary/tokens}

\item{embed_dim}{Number of word vectors}

\item{seq_len}{Length of the input sequences}

\item{hidden_dims}{Number of neurons per layer as vector of integers c(256, 128, 64)}

\item{hidden_fun}{Hidden activation function ("relu" by default)}

\item{output_fun}{Output activation function}

\item{output_dim}{Number of neurons of the output layer}
}
\value{
keras model
}
\description{
Word Embedding + Deep Multilayer Perceptron
}
